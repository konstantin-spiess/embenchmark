{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from  sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "from sentence_transformers import InputExample\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = [\n",
    "  \"all_languages\",\n",
    "  \"ar\",\n",
    "  \"de\",\n",
    "  \"de-en\",\n",
    "  \"de-fr\",\n",
    "  \"de-pl\",\n",
    "  \"en\",\n",
    "  \"es\",\n",
    "  \"es-en\",\n",
    "  \"es-it\",\n",
    "  \"fr\",\n",
    "  \"fr-pl\",\n",
    "  \"it\",\n",
    "  \"pl\",\n",
    "  \"pl-en\",\n",
    "  \"ru\",\n",
    "  \"tr\",\n",
    "  \"zh\",\n",
    "  \"zh-en\"\n",
    "]\n",
    "\n",
    "sts22 = {}\n",
    "\n",
    "for subset in subsets:\n",
    "  sts22[subset] = load_dataset(\"mteb/sts22-crosslingual-sts\", subset, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPlts(datasets, datasetKeys: list[str] , bins: list[int]):\n",
    "  word_count = {}\n",
    "  for i in datasetKeys:\n",
    "    word_count[i] = [len(x.split()) for x in datasets[i][\"sentence1\"]]\n",
    "\n",
    "  num_subplots = len(datasetKeys)\n",
    "  num_cols = 7\n",
    "  num_rows = num_subplots // num_cols + 1\n",
    "\n",
    "  fig, axes = fig, axes = plt.subplots(num_rows, num_cols, figsize=(5*num_cols, 5*num_rows))\n",
    "  axes = axes.flatten()\n",
    "\n",
    "  for idx, subset in enumerate(datasetKeys):\n",
    "    data = word_count[subset]\n",
    "    axes[idx].hist(data, bins=bins, edgecolor=\"black\")\n",
    "    axes[idx].set_title(subset)\n",
    "    axes[idx].set_xlabel('Word count')\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "\n",
    "    counts, _ = np.histogram(data, bins=bins)\n",
    "    max_count = max(counts)\n",
    "    if max_count <= 50:\n",
    "      axes[idx].set_ylim(0, 50)\n",
    "    elif max_count <= 200:\n",
    "      axes[idx].set_ylim(0, 200)\n",
    "    elif max_count <= 500:\n",
    "      axes[idx].set_ylim(0, 500)\n",
    "    elif max_count <= 1000:\n",
    "      axes[idx].set_ylim(0, 1000)\n",
    "    else:\n",
    "      axes[idx].set_ylim(0, 2000)\n",
    "\n",
    "  for i in range(num_subplots, num_rows * num_cols):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BINS = [0, 80, 200, 400, 1000]\n",
    "# SUBSETS = [\"de\"]\n",
    "SUBSETS = subsets\n",
    "createPlts(sts22, SUBSETS, BINS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = {}\n",
    "for subset in SUBSETS:\n",
    "    samples_subset = {}\n",
    "    for idx in range(len(BINS)-1):\n",
    "        key = f\"{BINS[idx]}-{BINS[idx+1]}\"\n",
    "        samples_subset[key] = [InputExample(texts=[item[\"sentence1\"], item[\"sentence2\"]], label=item[\"score\"]/5) for item in sts22[subset] if BINS[idx] <= len(item[\"sentence1\"].split()) < BINS[idx+1]]   \n",
    "    samples[subset] = samples_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluators = {}\n",
    "\n",
    "for subset in SUBSETS:\n",
    "    evaluators_subset = {}\n",
    "    samples_subset = samples[subset]\n",
    "    for i in range(len(BINS)-1):\n",
    "        key = f\"{BINS[i]}-{BINS[i+1]}\"\n",
    "        evaluators_subset[key] = EmbeddingSimilarityEvaluator.from_input_examples(samples_subset[key], name=f\"sts22-{key}\")\n",
    "    evaluators[subset] = evaluators_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "  \"jinaai/jina-embeddings-v2-small-en\",\n",
    "  \"jinaai/jina-embeddings-v2-base-en\",\n",
    "  \"jinaai/jina-embeddings-v2-large-en\"\n",
    "]\n",
    "\n",
    "for model_name in models:\n",
    "  print(\"Evaluating model\", model_name)\n",
    "  model = SentenceTransformer(model_name)\n",
    "  for subset in evaluators:\n",
    "    print(\"Evaluating subset\", subset)\n",
    "    evaluators_subset = evaluators[subset]\n",
    "    for key in evaluators_subset:\n",
    "      print(\"Evaluating bin\", key)\n",
    "      evaluator = evaluators_subset[key]\n",
    "      output_path = f\"./results/sts22-{subset}/{model_name}/\"\n",
    "      os.makedirs(output_path, exist_ok=True)\n",
    "      evaluator(model, output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in models:\n",
    "  for subset in evaluators:\n",
    "    file_paths = []\n",
    "    extracted_data = {'Range': [], 'Cosine_Pearson': [], 'Sample Count': []}\n",
    "    for key in evaluators[subset]:\n",
    "      file_path = f\"./results/sts22/sts22-{subset}/{model_name}/similarity_evaluation_sts22-{key}_results.csv\"\n",
    "      file_paths.append(file_path)\n",
    "\n",
    "      df = pd.read_csv(file_path)\n",
    "      # get last row\n",
    "      cosine_pearson = df['cosine_pearson'].iloc[-1]\n",
    "      extracted_data['Range'].append(key)\n",
    "      extracted_data['Cosine_Pearson'].append(cosine_pearson)\n",
    "      extracted_data['Sample Count'].append(len(samples[subset][key]))\n",
    "    extracted_df = pd.DataFrame(extracted_data)\n",
    "    print(\"Subset\", subset)\n",
    "    print(extracted_df) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

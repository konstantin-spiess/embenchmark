{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from  sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "from sentence_transformers import InputExample\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = [\n",
    "  \"all_languages\",\n",
    "  \"ar\",\n",
    "  \"de\",\n",
    "  \"de-en\",\n",
    "  \"de-fr\",\n",
    "  \"de-pl\",\n",
    "  \"en\",\n",
    "  \"es\",\n",
    "  \"es-en\",\n",
    "  \"es-it\",\n",
    "  \"fr\",\n",
    "  \"fr-pl\",\n",
    "  \"it\",\n",
    "  \"pl\",\n",
    "  \"pl-en\",\n",
    "  \"ru\",\n",
    "  \"tr\",\n",
    "  \"zh\",\n",
    "  \"zh-en\"\n",
    "]\n",
    "\n",
    "sts22 = {}\n",
    "\n",
    "for subset in subsets:\n",
    "  sts22[subset] = load_dataset(\"mteb/sts22-crosslingual-sts\", subset, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPlts(datasets, datasetKeys: list[str] , bins: list[int]):\n",
    "  word_count = {}\n",
    "  for i in datasetKeys:\n",
    "    word_count[i] = [len(x.split()) for x in datasets[i][\"sentence1\"]]\n",
    "\n",
    "  num_subplots = len(datasetKeys)\n",
    "  num_cols = 7\n",
    "  num_rows = num_subplots // num_cols + 1\n",
    "\n",
    "  fig, axes = fig, axes = plt.subplots(num_rows, num_cols, figsize=(5*num_cols, 5*num_rows))\n",
    "  axes = axes.flatten()\n",
    "\n",
    "  for idx, subset in enumerate(datasetKeys):\n",
    "    data = word_count[subset]\n",
    "    axes[idx].hist(data, bins=bins, edgecolor=\"black\")\n",
    "    axes[idx].set_title(subset)\n",
    "    axes[idx].set_xlabel('Word count')\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "\n",
    "    counts, _ = np.histogram(data, bins=bins)\n",
    "    max_count = max(counts)\n",
    "    if max_count <= 50:\n",
    "      axes[idx].set_ylim(0, 50)\n",
    "    elif max_count <= 200:\n",
    "      axes[idx].set_ylim(0, 200)\n",
    "    elif max_count <= 500:\n",
    "      axes[idx].set_ylim(0, 500)\n",
    "    elif max_count <= 1000:\n",
    "      axes[idx].set_ylim(0, 1000)\n",
    "    else:\n",
    "      axes[idx].set_ylim(0, 2000)\n",
    "\n",
    "  for i in range(num_subplots, num_rows * num_cols):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiQAAAHqCAYAAAA0+VUpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA270lEQVR4nO3df3BU9b3/8dc2JGvgJoEQks2WEFJ+qBBkBCxI0SQIkSC/vQIFBCpSrYBwgdFSryP0doDqiLZSkbYYoNJC2wFqhapBEn4IKL8lSCFiJEESUjDkF7AJyfn+4bBflyRAlg2fTfJ8zJwZzud8ztn3x7Obffk5Z3dtlmVZAgAAMOh7pgsAAAAgkAAAAOMIJAAAwDgCCQAAMI5AAgAAjCOQAAAA4wgkAADAOAIJAAAwjkACAACMI5AAAADjCCQAAMA4AgkAADCOQALAL2VlZWncuHGKjIyU3W7X3Xffrd/97nfu7RkZGbLZbPrLX/6iF154QU6nU6GhoRowYICOHz9usHIA3iCQAPA7n3/+ue677z5lZmbq1Vdf1XvvvadHHnlEzz77rBYsWODR9xe/+IVOnTqlP/7xj/r973+vrKwsDR06VJWVlYaqB+CNZqYLAIBrzZ49WyEhIdq5c6dCQ0MlSQMHDpTL5dLixYv17LPPuvt26dJF77zzjns9ICBAo0eP1t69e9WnT5/bXjsA7zBDAsCvXL58WR999JFGjhyp5s2b68qVK+5l8ODBunz5svbs2ePuP2zYMI/977nnHknSqVOnbmvdAG4NgQSAXzl//ryuXLmiN954Q4GBgR7L4MGDJUnnzp1z92/durXH/na7XZJ06dKl21c0gFvGJRsAfqVVq1YKCAjQ448/rmnTptXYJy4uTkeOHLnNlQGoTwQSAH6lefPmSkpK0sGDB3XPPfcoKCjIdEkAbgMCCQC/85vf/Eb9+vXTAw88oJ/97Gdq3769SkpK9MUXX+if//yntm7darpEAD5GIAHgd7p06aIDBw7o//7v//S///u/KigoUMuWLdWpUyf3fSQAGhebZVmW6SIAAEDTxqdsAACAcQQSAABgHIEEAAAYZzSQLFq0SPfdd59CQkIUGRmpESNGVPtRLMuyNH/+fDmdTgUHBysxMVFHjx716ONyuTRjxgxFRESoRYsWGjZsmE6fPn07hwIAAG6B0UCybds2TZs2TXv27FFaWpquXLmi5ORklZWVufu8/PLLWrJkiZYuXaq9e/fK4XBo4MCBKikpcfeZNWuWNmzYoLVr12rnzp0qLS3VkCFD+HEtAAAaCL/6lM1//vMfRUZGatu2bXrwwQdlWZacTqdmzZql559/XtK3syFRUVH69a9/raeeekpFRUVq06aN/vSnP2nMmDGSpDNnzigmJkabN2/Www8/bHJIAADgJvjV95AUFRVJksLDwyVJ2dnZys/PV3JysruP3W5XQkKCdu3apaeeekr79+9XRUWFRx+n06n4+Hjt2rWrxkDicrnkcrnc61VVVfrmm2/UunVr2Wy2+hoeAABNimVZKikpkdPp1Pe+d/2LMn4TSCzL0uzZs9WvXz/Fx8dLkvLz8yVJUVFRHn2joqLcv+SZn5+voKAgtWrVqlqfq/tfa9GiRVqwYIGvhwAAAGqQm5urtm3bXreP3wSS6dOn67PPPtPOnTurbbt21sKyrBvOZFyvz7x58zR79mz3elFRkdq1a6fc3FyFhoZ6UT0AALhWcXGxYmJiFBIScsO+fhFIZsyYoXfffVfbt2/3SFAOh0PSt7Mg0dHR7vaCggL3rInD4VB5ebkKCws9ZkkKCgrUt2/fGh/Pbre7f6L8u0JDQwkkAAD42M3cDmH0UzaWZWn69Olav369tm7dqri4OI/tcXFxcjgcSktLc7eVl5dr27Zt7rDRs2dPBQYGevTJy8tTZmZmrYEEAAD4F6MzJNOmTdOf//xn/eMf/1BISIj7no+wsDAFBwfLZrNp1qxZWrhwoTp16qROnTpp4cKFat68ucaNG+fuO2XKFM2ZM0etW7dWeHi45s6dq27dumnAgAEmhwcAAG6S0UCybNkySVJiYqJHe2pqqiZPnixJeu6553Tp0iU988wzKiwsVO/evfXhhx96XI967bXX1KxZM40ePVqXLl3SQw89pJUrVyogIOB2DQUAANwCv/oeElOKi4sVFhamoqIi7iEBAMBH6vL+ym/ZAAAA4wgkAADAOAIJAAAwjkACAACMI5AAAADjCCQAAMA4AgkAADCOQAIAAIwjkAAAAOMIJAAAwDgCCQAAMI5AAgAAjCOQAAAA4wgkAADAOAIJAAAwjkACAACMI5AAAADjCCQAAMA4AgkAADCOQAIAAIwjkAAAAOMIJAAAwDgCCQAAMI5AAgAAjCOQAAAA4wgkAADAOAIJAAAwjkACAACMI5AAAADjCCQAAMA4AgkAADCOQAIAAIwjkAAAAOMIJAAAwDgCCQAAMI5AAgAAjCOQAAAA4wgkAADAOAIJAAAwjkACAACMMxpItm/frqFDh8rpdMpms2njxo0e2202W43LK6+84u6TmJhYbfvYsWNv80gAAMCtMBpIysrK1L17dy1durTG7Xl5eR7L22+/LZvNpkcffdSj39SpUz36LV++/HaUDwAAfKSZyQdPSUlRSkpKrdsdDofH+j/+8Q8lJSXpBz/4gUd78+bNq/UFAAANR4O5h+Ts2bPatGmTpkyZUm3bmjVrFBERoa5du2ru3LkqKSm57rFcLpeKi4s9FgAAYI7RGZK6WLVqlUJCQjRq1CiP9vHjxysuLk4Oh0OZmZmaN2+eDh8+rLS0tFqPtWjRIi1YsKC+SwYAADfJZlmWZboI6dsbWDds2KARI0bUuP2uu+7SwIED9cYbb1z3OPv371evXr20f/9+9ejRo8Y+LpdLLpfLvV5cXKyYmBgVFRUpNDTU6zEAAID/r7i4WGFhYTf1/togZkh27Nih48ePa926dTfs26NHDwUGBiorK6vWQGK322W3231dJgAA8FKDuIdkxYoV6tmzp7p3737DvkePHlVFRYWio6NvQ2UAAMAXjM6QlJaW6osvvnCvZ2dn69ChQwoPD1e7du0kfTvd87e//U2vvvpqtf1PnjypNWvWaPDgwYqIiNDnn3+uOXPm6N5779WPfvSj2zYOAABwa4wGkn379ikpKcm9Pnv2bEnSpEmTtHLlSknS2rVrZVmWfvzjH1fbPygoSB999JF+85vfqLS0VDExMXrkkUf00ksvKSAg4LaMAQAA3Dq/uanVpLrcdAMAAG5OXd5fG8Q9JAAAoHEjkAAAAOMIJAAAwDgCCQAAMI5AAgAAjCOQAAAA4wgkAADAOAIJAAAwjkACAACMI5AAAADjCCQAAMA4AgkAADCOQAIAAIwjkAAAAOMIJAAAwDgCCQAAMI5AAgAAjCOQAAAA4wgkAADAOAIJAAAwjkACAACMI5AAAADjCCQAAMA4AgkAADCOQAIAAIwjkAAAAOMIJAAAwDgCCQAAMI5AAgAAjCOQAAAA4wgkAADAOAIJAAAwjkACAACMI5AAAADjCCQAAMA4AgkAADCOQAIAAIwjkAAAAOMIJAAAwDijgWT79u0aOnSonE6nbDabNm7c6LF98uTJstlsHkufPn08+rhcLs2YMUMRERFq0aKFhg0bptOnT9/GUQAAgFtlNJCUlZWpe/fuWrp0aa19Bg0apLy8PPeyefNmj+2zZs3Shg0btHbtWu3cuVOlpaUaMmSIKisr67t8AADgI81MPnhKSopSUlKu28dut8vhcNS4raioSCtWrNCf/vQnDRgwQJL0zjvvKCYmRlu2bNHDDz/s85oBAIDv+f09JBkZGYqMjFTnzp01depUFRQUuLft379fFRUVSk5Odrc5nU7Fx8dr165dJsoFAABeMDpDciMpKSl67LHHFBsbq+zsbL344ovq37+/9u/fL7vdrvz8fAUFBalVq1Ye+0VFRSk/P7/W47pcLrlcLvd6cXFxvY0BAADcmF8HkjFjxrj/HR8fr169eik2NlabNm3SqFGjat3PsizZbLZaty9atEgLFizwaa0AAMB7fn/J5ruio6MVGxurrKwsSZLD4VB5ebkKCws9+hUUFCgqKqrW48ybN09FRUXuJTc3t17rBgAA19egAsn58+eVm5ur6OhoSVLPnj0VGBiotLQ0d5+8vDxlZmaqb9++tR7HbrcrNDTUYwEAAOYYvWRTWlqqL774wr2enZ2tQ4cOKTw8XOHh4Zo/f74effRRRUdH66uvvtIvfvELRUREaOTIkZKksLAwTZkyRXPmzFHr1q0VHh6uuXPnqlu3bu5P3QAAAP9nNJDs27dPSUlJ7vXZs2dLkiZNmqRly5bpyJEjWr16tS5cuKDo6GglJSVp3bp1CgkJce/z2muvqVmzZho9erQuXbqkhx56SCtXrlRAQMBtHw8AAPCOzbIsy3QRphUXFyssLExFRUVcvgEAwEfq8v7aoO4hAQAAjROBBAAAGEcgAQAAxhFIAACAcQQSAABgHIEEAAAYRyABAADGEUgAAIBxBBIAAGAcgQQAABhHIAEAAMYRSAAAgHEEEgAAYByBBAAAGEcgAQAAxhFIAACAcQQSAABgHIEEAAAYRyABAADGEUgAAIBxBBIAAGAcgQQAABhHIAEAAMYRSAAAgHEEEgAAYByBBAAAGEcgAQAAxhFIAACAcQQSAABgHIEEAAAYRyABAADGEUgAAIBxBBIAAGAcgQQAABhHIAEAAMYRSAAAgHEEEgAAYByBBAAAGEcgAQAAxhFIAACAcUYDyfbt2zV06FA5nU7ZbDZt3LjRva2iokLPP/+8unXrphYtWsjpdGrixIk6c+aMxzESExNls9k8lrFjx97mkQAAgFthNJCUlZWpe/fuWrp0abVtFy9e1IEDB/Tiiy/qwIEDWr9+vU6cOKFhw4ZV6zt16lTl5eW5l+XLl9+O8gEAgI80M/ngKSkpSklJqXFbWFiY0tLSPNreeOMN/fCHP1ROTo7atWvnbm/evLkcDke91goAAOpPg7qHpKioSDabTS1btvRoX7NmjSIiItS1a1fNnTtXJSUlZgoEAABeMTpDUheXL1/Wz3/+c40bN06hoaHu9vHjxysuLk4Oh0OZmZmaN2+eDh8+XG125btcLpdcLpd7vbi4uF5rBwAA19cgAklFRYXGjh2rqqoqvfnmmx7bpk6d6v53fHy8OnXqpF69eunAgQPq0aNHjcdbtGiRFixYUK81AwCAm+f3l2wqKio0evRoZWdnKy0tzWN2pCY9evRQYGCgsrKyau0zb948FRUVuZfc3Fxflw0AAOrAr2dIroaRrKwspaenq3Xr1jfc5+jRo6qoqFB0dHStfex2u+x2uy9LBQAAt8BoICktLdUXX3zhXs/OztahQ4cUHh4up9Op//7v/9aBAwf03nvvqbKyUvn5+ZKk8PBwBQUF6eTJk1qzZo0GDx6siIgIff7555ozZ47uvfde/ehHPzI1LAAAUEc2y7IsUw+ekZGhpKSkau2TJk3S/PnzFRcXV+N+6enpSkxMVG5uriZMmKDMzEyVlpYqJiZGjzzyiF566SWFh4ffdB3FxcUKCwtTUVHRDS8JAQCAm1OX91ejgcRfEEgAAPC9ury/+v1NrQAAoPEjkAAAAOMIJAAAwDgCCQAAMI5AAgAAjCOQAAAA4wgkAADAOAIJAAAwjkACAACMI5AAAADjCCQAAMA4rwJJdna2r+sAAABNmFeBpGPHjkpKStI777yjy5cv+7omAADQxHgVSA4fPqx7771Xc+bMkcPh0FNPPaVPP/3U17UBAIAmwqtAEh8fryVLlujrr79Wamqq8vPz1a9fP3Xt2lVLlizRf/7zH1/XCQAAGrFbuqm1WbNmGjlypP7617/q17/+tU6ePKm5c+eqbdu2mjhxovLy8nxVJwAAaMRuKZDs27dPzzzzjKKjo7VkyRLNnTtXJ0+e1NatW/X1119r+PDhvqoTAAA0Ys282WnJkiVKTU3V8ePHNXjwYK1evVqDBw/W9773bb6Ji4vT8uXLddddd/m0WAAA0Dh5FUiWLVumJ554Qj/5yU/kcDhq7NOuXTutWLHilooDAABNg82yLMt0EaYVFxcrLCxMRUVFCg0NNV0OAACNQl3eX726hyQ1NVV/+9vfqrX/7W9/06pVq7w5JAAAaMK8CiSLFy9WREREtfbIyEgtXLjwlosCAABNi1eB5NSpU4qLi6vWHhsbq5ycnFsuCgAANC1eBZLIyEh99tln1doPHz6s1q1b33JRAACgafEqkIwdO1bPPvus0tPTVVlZqcrKSm3dulUzZ87U2LFjfV0jAABo5Lz62O+vfvUrnTp1Sg899JCaNfv2EFVVVZo4cSL3kAAAgDq7pY/9njhxQocPH1ZwcLC6deum2NhYX9Z22/CxXwAAfK8u769ezZBc1blzZ3Xu3PlWDgEAAOBdIKmsrNTKlSv10UcfqaCgQFVVVR7bt27d6pPiAABA0+BVIJk5c6ZWrlypRx55RPHx8bLZbL6uCwAANCFeBZK1a9fqr3/9qwYPHuzregAAQBPk1cd+g4KC1LFjR1/XAgAAmiivAsmcOXP0m9/8RvwuHwAA8AWvLtns3LlT6enp+te//qWuXbsqMDDQY/v69et9UhwAAGgavAokLVu21MiRI31dCwAAaKK8CiSpqam+rgMAADRhXt1DIklXrlzRli1btHz5cpWUlEiSzpw5o9LSUp8VBwAAmgavZkhOnTqlQYMGKScnRy6XSwMHDlRISIhefvllXb58WW+99Zav6wQAAI2YVzMkM2fOVK9evVRYWKjg4GB3+8iRI/XRRx/5rDgAANA0eP0pm48//lhBQUEe7bGxsfr66699UhgAAGg6vJohqaqqUmVlZbX206dPKyQk5KaPs337dg0dOlROp1M2m00bN2702G5ZlubPny+n06ng4GAlJibq6NGjHn1cLpdmzJihiIgItWjRQsOGDdPp06e9GRYAADDEq0AycOBAvf766+51m82m0tJSvfTSS3X6OvmysjJ1795dS5curXH7yy+/rCVLlmjp0qXau3evHA6HBg4c6L6JVpJmzZqlDRs2aO3atdq5c6dKS0s1ZMiQGgMTAADwTzbLi69bPXPmjJKSkhQQEKCsrCz16tVLWVlZioiI0Pbt2xUZGVn3Qmw2bdiwQSNGjJD07eyI0+nUrFmz9Pzzz0v6djYkKipKv/71r/XUU0+pqKhIbdq00Z/+9CeNGTPGXVtMTIw2b96shx9++KYeu7i4WGFhYSoqKlJoaGidawcAANXV5f3VqxkSp9OpQ4cOae7cuXrqqad07733avHixTp48KBXYaQm2dnZys/PV3JysrvNbrcrISFBu3btkiTt379fFRUVHn2cTqfi4+PdfQAAgP/z6qZWSQoODtYTTzyhJ554wpf1uOXn50uSoqKiPNqjoqJ06tQpd5+goCC1atWqWp+r+9fE5XLJ5XK514uLi31VNgAA8IJXgWT16tXX3T5x4kSviqmJzWbzWLcsq1rbtW7UZ9GiRVqwYIFP6gMAALfOq0Ayc+ZMj/WKigpdvHhRQUFBat68uU8CicPhkPTtLEh0dLS7vaCgwD1r4nA4VF5ersLCQo9ZkoKCAvXt27fWY8+bN0+zZ892rxcXFysmJuaWawYAAN7x6h6SwsJCj6W0tFTHjx9Xv3799Je//MUnhcXFxcnhcCgtLc3dVl5erm3btrnDRs+ePRUYGOjRJy8vT5mZmdcNJHa7XaGhoR4LAAAwx+t7SK7VqVMnLV68WBMmTNC///3vm9qntLRUX3zxhXs9Oztbhw4dUnh4uNq1a6dZs2Zp4cKF6tSpkzp16qSFCxeqefPmGjdunCQpLCxMU6ZM0Zw5c9S6dWuFh4dr7ty56tatmwYMGOCroQEAgHrms0AiSQEBATpz5sxN99+3b5+SkpLc61cvo0yaNEkrV67Uc889p0uXLumZZ55RYWGhevfurQ8//NDjy9dee+01NWvWTKNHj9alS5f00EMPaeXKlQoICPDdwAAAQL3y6ntI3n33XY91y7KUl5enpUuXKiYmRv/61798VuDtwPeQAADge3V5f/VqhuTql5ddZbPZ1KZNG/Xv31+vvvqqN4cEAABNmFeBpKqqytd1AACAJsyrT9kAAAD4klczJN/9Do8bWbJkiTcPAQAAmhCvAsnBgwd14MABXblyRXfeeack6cSJEwoICFCPHj3c/W70jaoAAACSl4Fk6NChCgkJ0apVq9zfkFpYWKif/OQneuCBBzRnzhyfFgkAABo3rz72+/3vf18ffvihunbt6tGemZmp5OTkOn0XiT/gY78AAPheXd5fvbqptbi4WGfPnq3WXlBQoJKSEm8OCQAAmjCvAsnIkSP1k5/8RH//+991+vRpnT59Wn//+981ZcoUjRo1ytc1AgCARs6re0jeeustzZ07VxMmTFBFRcW3B2rWTFOmTNErr7zi0wIBAEDj59U9JFeVlZXp5MmTsixLHTt2VIsWLXxZ223DPSQAAPhevd9DclVeXp7y8vLUuXNntWjRQreQbQAAQBPmVSA5f/68HnroIXXu3FmDBw9WXl6eJOnJJ5/kI78AAKDOvAok//M//6PAwEDl5OSoefPm7vYxY8bo/fff91lxAACgafDqptYPP/xQH3zwgdq2bevR3qlTJ506dconhQEAgKbDqxmSsrIyj5mRq86dOye73X7LRQEAgKbFq0Dy4IMPavXq1e51m82mqqoqvfLKK0pKSvJZcQAAoGnw6pLNK6+8osTERO3bt0/l5eV67rnndPToUX3zzTf6+OOPfV0jAABo5LyaIenSpYs+++wz/fCHP9TAgQNVVlamUaNG6eDBg+rQoYOvawQAAI1cnWdIKioqlJycrOXLl2vBggX1URMAAGhi6jxDEhgYqMzMTNlstvqoBwAANEFeXbKZOHGiVqxY4etaAABAE+XVTa3l5eX64x//qLS0NPXq1avab9gsWbLEJ8UBAICmoU6B5Msvv1T79u2VmZmpHj16SJJOnDjh0YdLOQAAoK7qFEg6deqkvLw8paenS/r2q+J/+9vfKioqql6KAwAATUOd7iG59td8//Wvf6msrMynBQEAgKbHq5tar7o2oAAAAHijToHEZrNVu0eEe0YAAMCtqtM9JJZlafLkye4f0Lt8+bKefvrpap+yWb9+ve8qBAAAjV6dAsmkSZM81idMmODTYgAAQNNUp0CSmppaX3UAAIAm7JZuagUAAPAFAgkAADCOQAIAAIwjkAAAAOMIJAAAwDgCCQAAMI5AAgAAjCOQAAAA4wgkAADAOL8PJO3bt3f/qN93l2nTpkmSJk+eXG1bnz59DFcNAADqok5fHW/C3r17VVlZ6V7PzMzUwIED9dhjj7nbBg0a5PG19kFBQbe1RgAAcGv8PpC0adPGY33x4sXq0KGDEhIS3G12u10Oh+N2lwYAAHzE7y/ZfFd5ebneeecdPfHEE7LZbO72jIwMRUZGqnPnzpo6daoKCgquexyXy6Xi4mKPBQAAmNOgAsnGjRt14cIFTZ482d2WkpKiNWvWaOvWrXr11Ve1d+9e9e/fXy6Xq9bjLFq0SGFhYe4lJibmNlQPAABqY7MsyzJdxM16+OGHFRQUpH/+85+19snLy1NsbKzWrl2rUaNG1djH5XJ5BJbi4mLFxMSoqKhIoaGhPq8bAICmqLi4WGFhYTf1/ur395BcderUKW3ZskXr16+/br/o6GjFxsYqKyur1j52u112u93XJQIAAC81mEs2qampioyM1COPPHLdfufPn1dubq6io6NvU2UAAOBWNYhAUlVVpdTUVE2aNEnNmv3/SZ3S0lLNnTtXu3fv1ldffaWMjAwNHTpUERERGjlypMGKAQBAXTSISzZbtmxRTk6OnnjiCY/2gIAAHTlyRKtXr9aFCxcUHR2tpKQkrVu3TiEhIYaqbZhycnJ07tw502XclIiICLVr1850GQAAH2pQN7XWl7rcdNMY5eTk6M677tblSxdNl3JT7ghuruP/PkYoAQA/1yhvakX9OXfunC5fuqjWQ+YosLV/fwS64nyuzr/3qs6dO0cgAYBGhEACt8DWMbI7OpouAwDQBBFI0CAdO3bMdAkwiPuIgMaHQIIGpbK0ULLZNGHCBNOlwCDuIwIaHwIJGpQqV6lkWQ3ifhfUD+4jAhonAgkaJO53AYDGpUF8MRoAAGjcCCQAAMA4AgkAADCOQAIAAIwjkAAAAOMIJAAAwDgCCQAAMI5AAgAAjCOQAAAA4wgkAADAOAIJAAAwjkACAACMI5AAAADjCCQAAMA4AgkAADCOQAIAAIwjkAAAAOMIJAAAwDgCCQAAMI5AAgAAjCOQAAAA4wgkAADAOAIJAAAwjkACAACMI5AAAADjCCQAAMA4AgkAADCOQAIAAIwjkAAAAOMIJAAAwDgCCQAAMI5AAgAAjCOQAAAA4wgkAADAOL8OJPPnz5fNZvNYHA6He7tlWZo/f76cTqeCg4OVmJioo0ePGqwYAAB4w68DiSR17dpVeXl57uXIkSPubS+//LKWLFmipUuXau/evXI4HBo4cKBKSkoMVgwAAOrK7wNJs2bN5HA43EubNm0kfTs78vrrr+uFF17QqFGjFB8fr1WrVunixYv685//bLhqAABQF34fSLKysuR0OhUXF6exY8fqyy+/lCRlZ2crPz9fycnJ7r52u10JCQnatWvXdY/pcrlUXFzssQAAAHP8OpD07t1bq1ev1gcffKA//OEPys/PV9++fXX+/Hnl5+dLkqKiojz2iYqKcm+rzaJFixQWFuZeYmJi6m0MAADgxvw6kKSkpOjRRx9Vt27dNGDAAG3atEmStGrVKncfm83msY9lWdXarjVv3jwVFRW5l9zcXN8XDwAAbppfB5JrtWjRQt26dVNWVpb70zbXzoYUFBRUmzW5lt1uV2hoqMcCAADMaVCBxOVy6dixY4qOjlZcXJwcDofS0tLc28vLy7Vt2zb17dvXYJUAAKCumpku4Hrmzp2roUOHql27diooKNCvfvUrFRcXa9KkSbLZbJo1a5YWLlyoTp06qVOnTlq4cKGaN2+ucePGmS4dAADUgV8HktOnT+vHP/6xzp07pzZt2qhPnz7as2ePYmNjJUnPPfecLl26pGeeeUaFhYXq3bu3PvzwQ4WEhBiuHAAA1IVfB5K1a9ded7vNZtP8+fM1f/7821MQAACoFw3qHhIAANA4EUgAAIBxBBIAAGAcgQQAABhHIAEAAMYRSAAAgHEEEgAAYByBBAAAGEcgAQAAxhFIAACAcQQSAABgHIEEAAAYRyABAADGEUgAAIBxBBIAAGAcgQQAABhHIAEAAMY1M11AY5aTk6Nz586ZLuOGjh07ZroEAEATRyCpJzk5Obrzrrt1+dJF06UAAOD3CCT15Ny5c7p86aJaD5mjwNYxpsu5rktf7lPRjndMlwEAaMIIJPUssHWM7I6Opsu4rorzuaZLAAA0cdzUCgAAjCOQAAAA4wgkAADAOAIJAAAwjkACAACMI5AAAADjCCQAAMA4AgkAADCOQAIAAIwjkAAAAOMIJAAAwDgCCQAAMI5AAgAAjCOQAAAA4wgkAADAOAIJAAAwjkACAACMI5AAAADj/DqQLFq0SPfdd59CQkIUGRmpESNG6Pjx4x59Jk+eLJvN5rH06dPHUMUAAMAbfh1Itm3bpmnTpmnPnj1KS0vTlStXlJycrLKyMo9+gwYNUl5ennvZvHmzoYoBAIA3mpku4Href/99j/XU1FRFRkZq//79evDBB93tdrtdDofjdpcHAAB8xK9nSK5VVFQkSQoPD/doz8jIUGRkpDp37qypU6eqoKDARHkAAMBLfj1D8l2WZWn27Nnq16+f4uPj3e0pKSl67LHHFBsbq+zsbL344ovq37+/9u/fL7vdXuOxXC6XXC6Xe724uLje6wcAALVrMIFk+vTp+uyzz7Rz506P9jFjxrj/HR8fr169eik2NlabNm3SqFGjajzWokWLtGDBgnqtFwAA3LwGcclmxowZevfdd5Wenq62bdtet290dLRiY2OVlZVVa5958+apqKjIveTm5vq6ZAAAUAd+PUNiWZZmzJihDRs2KCMjQ3FxcTfc5/z588rNzVV0dHStfex2e62XcwAAwO3n1zMk06ZN0zvvvKM///nPCgkJUX5+vvLz83Xp0iVJUmlpqebOnavdu3frq6++UkZGhoYOHaqIiAiNHDnScPUAAOBm+fUMybJlyyRJiYmJHu2pqamaPHmyAgICdOTIEa1evVoXLlxQdHS0kpKStG7dOoWEhBioGAAAeMOvA4llWdfdHhwcrA8++OA2VQMAAOqLX1+yAQAATQOBBAAAGEcgAQAAxhFIAACAcQQSAABgHIEEAAAYRyABAADGEUgAAIBxBBIAAGAcgQQAABhHIAEAAMb59W/ZAEBtjh07ZroEoNGJiIhQu3btjDw2gQRAg1JZWijZbJowYYLpUoBG547g5jr+72NGQgmBBECDUuUqlSxLrYfMUWDrGNPlAI1GxflcnX/vVZ07d45AAgA3K7B1jOyOjqbLAOAj3NQKAACMI5AAAADjCCQAAMA4AgkAADCOQAIAAIwjkAAAAOMIJAAAwDgCCQAAMI5AAgAAjCOQAAAA4wgkAADAOAIJAAAwjkACAACMI5AAAADjCCQAAMA4AgkAADCOQAIAAIwjkAAAAOMIJAAAwDgCCQAAMI5AAgAAjCOQAAAA4wgkAADAOAIJAAAwjkACAACMazSB5M0331RcXJzuuOMO9ezZUzt27DBdEgAAuEmNIpCsW7dOs2bN0gsvvKCDBw/qgQceUEpKinJyckyXBgAAbkKjCCRLlizRlClT9OSTT+ruu+/W66+/rpiYGC1btsx0aQAA4CY0+EBSXl6u/fv3Kzk52aM9OTlZu3btMlQVAACoi2amC7hV586dU2VlpaKiojzao6KilJ+fX+M+LpdLLpfLvV5UVCRJKi4u9lldpaWl3z5W/heqKr/ss+PWh4rzuZKoFQ0DzwGgflR8c1rSt+9fvno/vHocy7Ju2LfBB5KrbDabx7plWdXarlq0aJEWLFhQrT0mJsbndRV+sNTnx6wv1IqGhOcAUD8SEhJ8fsySkhKFhYVdt0+DDyQREREKCAioNhtSUFBQbdbkqnnz5mn27Nnu9aqqKn3zzTdq3bp1rSGmroqLixUTE6Pc3FyFhob65Jj+gHE1HI1xTBLjamga47ga45ik+hmXZVkqKSmR0+m8Yd8GH0iCgoLUs2dPpaWlaeTIke72tLQ0DR8+vMZ97Ha77Ha7R1vLli3rpb7Q0NBG9YS9inE1HI1xTBLjamga47ga45gk34/rRjMjVzX4QCJJs2fP1uOPP65evXrp/vvv1+9//3vl5OTo6aefNl0aAAC4CY0ikIwZM0bnz5/XL3/5S+Xl5Sk+Pl6bN29WbGys6dIAAMBNaBSBRJKeeeYZPfPMM6bLcLPb7XrppZeqXRpq6BhXw9EYxyQxroamMY6rMY5JMj8um3Uzn8UBAACoRw3+i9EAAEDDRyABAADGEUgAAIBxBJJ68uabbyouLk533HGHevbsqR07dpguqVaLFi3Sfffdp5CQEEVGRmrEiBE6fvy4R5/JkyfLZrN5LH369PHo43K5NGPGDEVERKhFixYaNmyYTp8+fTuH4mH+/PnVanY4HO7tlmVp/vz5cjqdCg4OVmJioo4ePepxDH8bU/v27auNyWazadq0aZIaznnavn27hg4dKqfTKZvNpo0bN3ps99W5KSws1OOPP66wsDCFhYXp8ccf14ULF4yMq6KiQs8//7y6deumFi1ayOl0auLEiTpz5ozHMRITE6udw7Fjxxob143Ola+ec/50riTV+Dqz2Wx65ZVX3H387VzdzN9yf35tEUjqwbp16zRr1iy98MILOnjwoB544AGlpKQoJyfHdGk12rZtm6ZNm6Y9e/YoLS1NV65cUXJyssrKyjz6DRo0SHl5ee5l8+bNHttnzZqlDRs2aO3atdq5c6dKS0s1ZMgQVVZW3s7heOjatatHzUeOHHFve/nll7VkyRItXbpUe/fulcPh0MCBA1VSUuLu429j2rt3r8d40tLSJEmPPfaYu09DOE9lZWXq3r27li6t+evffXVuxo0bp0OHDun999/X+++/r0OHDunxxx83Mq6LFy/qwIEDevHFF3XgwAGtX79eJ06c0LBhw6r1nTp1qsc5XL58ucf22zmuG50ryTfPOX86V5I8xpOXl6e3335bNptNjz76qEc/fzpXN/O33K9fWxZ87oc//KH19NNPe7Tddddd1s9//nNDFdVNQUGBJcnatm2bu23SpEnW8OHDa93nwoULVmBgoLV27Vp329dff21973vfs95///36LLdWL730ktW9e/cat1VVVVkOh8NavHixu+3y5ctWWFiY9dZbb1mW5Z9jutbMmTOtDh06WFVVVZZlNczzJMnasGGDe91X5+bzzz+3JFl79uxx99m9e7clyfr3v/9dz6OqPq6afPrpp5Yk69SpU+62hIQEa+bMmbXuY3JcNY3JF8+5hnCuhg8fbvXv39+jzZ/PlWVV/1vu768tZkh8rLy8XPv371dycrJHe3Jysnbt2mWoqrq5+uvH4eHhHu0ZGRmKjIxU586dNXXqVBUUFLi37d+/XxUVFR7jdjqdio+PNzrurKwsOZ1OxcXFaezYsfryyy8lSdnZ2crPz/eo1263KyEhwV2vv47pqvLycr3zzjt64oknPH6DqSGep+/y1bnZvXu3wsLC1Lt3b3efPn36KCwszG/GWlRUJJvNVu2nK9asWaOIiAh17dpVc+fO9fi/V38c160+5/xxTN919uxZbdq0SVOmTKm2zZ/P1bV/y/39tdVovhjNX5w7d06VlZXVftgvKiqq2g8A+iPLsjR79mz169dP8fHx7vaUlBQ99thjio2NVXZ2tl588UX1799f+/fvl91uV35+voKCgtSqVSuP45kcd+/evbV69Wp17txZZ8+e1a9+9Sv17dtXR48edddU03k6deqUJPnlmL5r48aNunDhgiZPnuxua4jn6Vq+Ojf5+fmKjIysdvzIyEi/GOvly5f185//XOPGjfP43ZDx48crLi5ODodDmZmZmjdvng4fPuy+POdv4/LFc87fxnStVatWKSQkRKNGjfJo9+dzVdPfcn9/bRFI6sm1vxpsWZbPfkm4Pk2fPl2fffaZdu7c6dE+ZswY97/j4+PVq1cvxcbGatOmTdVepN9lctwpKSnuf3fr1k3333+/OnTooFWrVrlvuvPmPPnLuVyxYoVSUlI8fkWzIZ6n2vji3NTU3x/GWlFRobFjx6qqqkpvvvmmx7apU6e6/x0fH69OnTqpV69eOnDggHr06CHJv8blq+ecP43pWm+//bbGjx+vO+64w6Pdn89VbX/La6rJX15bXLLxsYiICAUEBFRLiQUFBdVSqb+ZMWOG3n33XaWnp6tt27bX7RsdHa3Y2FhlZWVJkhwOh8rLy1VYWOjRz5/G3aJFC3Xr1k1ZWVnuT9tc7zz585hOnTqlLVu26Mknn7xuv4Z4nnx1bhwOh86ePVvt+P/5z3+MjrWiokKjR49Wdna20tLSbvirqj169FBgYKDHOfTHcV3lzXPOn8e0Y8cOHT9+/IavNcl/zlVtf8v9/bVFIPGxoKAg9ezZ0z1ld1VaWpr69u1rqKrrsyxL06dP1/r167V161bFxcXdcJ/z588rNzdX0dHRkqSePXsqMDDQY9x5eXnKzMz0m3G7XC4dO3ZM0dHR7mnW79ZbXl6ubdu2uev15zGlpqYqMjJSjzzyyHX7NcTz5Ktzc//996uoqEiffvqpu88nn3yioqIiY2O9GkaysrK0ZcsWtW7d+ob7HD16VBUVFe5z6I/j+i5vnnP+PKYVK1aoZ8+e6t69+w37mj5XN/pb7vevLa9vh0Wt1q5dawUGBlorVqywPv/8c2vWrFlWixYtrK+++sp0aTX62c9+ZoWFhVkZGRlWXl6ee7l48aJlWZZVUlJizZkzx9q1a5eVnZ1tpaenW/fff7/1/e9/3youLnYf5+mnn7batm1rbdmyxTpw4IDVv39/q3v37taVK1eMjGvOnDlWRkaG9eWXX1p79uyxhgwZYoWEhLjPw+LFi62wsDBr/fr11pEjR6wf//jHVnR0tF+PybIsq7Ky0mrXrp31/PPPe7Q3pPNUUlJiHTx40Dp48KAlyVqyZIl18OBB96dNfHVuBg0aZN1zzz3W7t27rd27d1vdunWzhgwZYmRcFRUV1rBhw6y2bdtahw4d8nituVwuy7Is64svvrAWLFhg7d2718rOzrY2bdpk3XXXXda9995rbFzXG5Mvn3P+dK6uKioqspo3b24tW7as2v7+eK5u9Lfcsvz7tUUgqSe/+93vrNjYWCsoKMjq0aOHx0do/Y2kGpfU1FTLsizr4sWLVnJystWmTRsrMDDQateunTVp0iQrJyfH4ziXLl2ypk+fboWHh1vBwcHWkCFDqvW5ncaMGWNFR0dbgYGBltPptEaNGmUdPXrUvb2qqsp66aWXLIfDYdntduvBBx+0jhw54nEMfxuTZVnWBx98YEmyjh8/7tHekM5Tenp6jc+5SZMmWZblu3Nz/vx5a/z48VZISIgVEhJijR8/3iosLDQyruzs7Fpfa+np6ZZlWVZOTo714IMPWuHh4VZQUJDVoUMH69lnn7XOnz9vbFzXG5Mvn3P+dK6uWr58uRUcHGxduHCh2v7+eK5u9Lfcsvz7tcWv/QIAAOO4hwQAABhHIAEAAMYRSAAAgHEEEgAAYByBBAAAGEcgAQAAxhFIAACAcQQSAABgHIEEgN9q3769Xn/9ddNlALgNCCQAavTWW28pJCREV65ccbeVlpYqMDBQDzzwgEffHTt2yGaz6cSJE7e7TL9gs9m0ceNG02UADRqBBECNkpKSVFpaqn379rnbduzYIYfDob179+rixYvu9oyMDDmdTnXu3LnOj1NZWamqqiqf1Ayg4SKQAKjRnXfeKafTqYyMDHdbRkaGhg8frg4dOmjXrl0e7UlJSZKkwsJCTZw4Ua1atVLz5s2VkpKirKwsd9+VK1eqZcuWeu+999SlSxfZ7XadOnVKBQUFGjp0qIKDgxUXF6c1a9bcVJ1vv/22unbtKrvdrujoaE2fPt29LScnR8OHD9d//dd/KTQ0VKNHj9bZs2fd2ydPnqwRI0Z4HG/WrFlKTEx0rycmJurZZ5/Vc889p/DwcDkcDs2fP9+9vX379pKkkSNHymazudcB1A2BBECtEhMTlZ6e7l5PT09XYmKiEhIS3O3l5eXavXu3O5BMnjxZ+/bt07vvvqvdu3fLsiwNHjxYFRUV7uNcvHhRixYt0h//+EcdPXpUkZGRmjx5sr766itt3bpVf//73/Xmm2+qoKDguvUtW7ZM06ZN009/+lMdOXJE7777rjp27ChJsixLI0aM0DfffKNt27YpLS1NJ0+e1JgxY+r832HVqlVq0aKFPvnkE7388sv65S9/qbS0NEnS3r17JUmpqanKy8tzrwOoo1v6rWAAjdrvf/97q0WLFlZFRYVVXFxsNWvWzDp79qy1du1aq2/fvpZlWda2bdssSdbJkyetEydOWJKsjz/+2H2Mc+fOWcHBwdZf//pXy7IsKzU11ZJkHTp0yN3n+PHjliRrz5497rZjx45ZkqzXXnut1vqcTqf1wgsv1Ljtww8/tAICAjx+Nv3o0aOWJOvTTz+1LMuyJk2aZA0fPtxjv5kzZ1oJCQnu9YSEBKtfv34efe677z7r+eefd69LsjZs2FBrnQBujBkSALVKSkpSWVmZ9u7dqx07dqhz586KjIxUQkKC9u7dq7KyMmVkZKhdu3b6wQ9+oGPHjqlZs2bq3bu3+xitW7fWnXfeqWPHjrnbgoKCdM8997jXr+7Xq1cvd9tdd92lli1b1lpbQUGBzpw5o4ceeqjG7ceOHVNMTIxiYmLcbV26dFHLli09arkZ361VkqKjo284ewOgbpqZLgCA/+rYsaPatm2r9PR0FRYWKiEhQZLkcDgUFxenjz/+WOnp6erfv7+kby+T1MSyLNlsNvd6cHCwx/rV/b7bdiPBwcHX3X7tY9bU/r3vfa9azd+9tHRVYGCgx7rNZuNGXMDHmCEBcF1JSUnKyMhQRkaGx82eCQkJ+uCDD7Rnzx73/SNdunTRlStX9Mknn7j7nT9/XidOnNDdd99d62PcfffdunLliscneo4fP64LFy7Uuk9ISIjat2+vjz76qMbtXbp0UU5OjnJzc91tn3/+uYqKity1tGnTRnl5eR77HTp0qNbHrE1gYKAqKyvrvB+A/49AAuC6kpKStHPnTh06dMg9QyJ9G0j+8Ic/6PLly+5A0qlTJw0fPlxTp07Vzp07dfjwYU2YMEHf//73NXz48Fof484779SgQYM0depUffLJJ9q/f7+efPLJG86CzJ8/X6+++qp++9vfKisrSwcOHNAbb7whSRowYIDuuecejR8/XgcOHNCnn36qiRMnKiEhwX1pqH///tq3b59Wr16trKwsvfTSS8rMzKzzf6OrwSg/P1+FhYV13h8AgQTADSQlJenSpUvq2LGjoqKi3O0JCQkqKSlRhw4dPO7TSE1NVc+ePTVkyBDdf//9sixLmzdvrnbZ41qpqamKiYlRQkKCRo0apZ/+9KeKjIy87j6TJk3S66+/rjfffFNdu3bVkCFD3B8xvvplZa1atdKDDz6oAQMG6Ac/+IHWrVvn3v/hhx/Wiy++qOeee0733XefSkpKNHHixDr/N3r11VeVlpammJgY3XvvvXXeH4Bks2q76AsAAHCbMEMCAACMI5AAAADjCCQAAMA4AgkAADCOQAIAAIwjkAAAAOMIJAAAwDgCCQAAMI5AAgAAjCOQAAAA4wgkAADAOAIJAAAw7v8Bf6D4ki8XwygAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 3500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BINS = [0, 80, 200, 400, 1000, 2000]\n",
    "SUBSETS = [\"de\"]\n",
    "createPlts(sts22, SUBSETS, BINS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = {}\n",
    "for subset in SUBSETS:\n",
    "    samples_subset = {}\n",
    "    for idx in range(len(BINS)-1):\n",
    "        key = f\"{BINS[idx]}-{BINS[idx+1]}\"\n",
    "        samples_subset[key] = [InputExample(texts=[item[\"sentence1\"], item[\"sentence2\"]], label=item[\"score\"]/5) for item in sts22[subset] if BINS[idx] <= len(item[\"sentence1\"].split()) < BINS[idx+1]]   \n",
    "    samples[subset] = samples_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': {'0-200': [<sentence_transformers.readers.InputExample.InputExample at 0x2995ba5d0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x2995ba050>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f17e10>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f56810>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x2993f3e10>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f43810>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f25250>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f23d90>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288afbe50>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f575d0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b073d0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x2995a5b50>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307e5ced0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x2995aa510>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b064d0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b04ed0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307fa3b90>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b0be10>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b0bc10>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b0d8d0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b0bf10>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b0b310>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b0df90>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b0e090>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b0e950>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b0ec90>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b0ee90>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b0efd0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b0f350>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b0f790>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b0f890>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b0fd10>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b0ff10>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b0f210>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b0fe10>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b0c050>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b0fad0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b0fc10>],\n",
       "  '200-400': [<sentence_transformers.readers.InputExample.InputExample at 0x31f5b7950>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b06fd0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307fa1410>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307fa0910>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b13f90>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b13a90>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b14f50>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b15250>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b15510>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b13e50>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b15e50>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b162d0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b16b50>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b16d50>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b16fd0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b175d0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b17b50>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x2993d2910>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b17fd0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b17c50>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b17e90>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b19310>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b195d0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b19b10>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b19d10>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b17d50>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b1a0d0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b1a390>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b1a750>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b1aad0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b1ac10>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b1afd0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b1b210>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b1b490>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b1b710>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b1bad0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b1be50>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b1bf90>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b1bd10>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b1bc10>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b1bdd0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b1ba50>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b1b990>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b1cd90>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b1d5d0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b1d6d0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b1da90>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b1dbd0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b1e0d0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b1e1d0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x288b1e410>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307ea9210>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f23e10>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f24290>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f24210>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f1be90>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f1bf10>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f242d0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f1bfd0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f16b90>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x299148b10>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f16ad0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x2992a2610>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x294ee7f50>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f24390>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f157d0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f16a50>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f23290>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f23dd0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f23b50>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x294ecbad0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f23cd0>],\n",
       "  '400-1000': [<sentence_transformers.readers.InputExample.InputExample at 0x307f23a90>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307eb2ad0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x2994df8d0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x2994dda90>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307effad0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x29944f690>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f23a50>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x29933ecd0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x2993b2b10>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x2994b18d0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f23310>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307e77bd0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x2994bc150>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x2994bd490>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x2994bc450>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x2aad31050>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307e28790>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x294ef5610>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x299228110>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x2aad30190>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307e4f810>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f50b50>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307e4e150>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f50690>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f532d0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f50750>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f50b10>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f50a90>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f50810>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f50c10>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f50f10>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f6b310>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f6ad50>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f50710>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f69410>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f6b710>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f6ad90>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f6bc50>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f6af90>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f6bad0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f6b110>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f6bc90>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f6b650>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f6b150>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f6b4d0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f6b2d0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f69390>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f6b510>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f6b790>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f6b890>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f6b8d0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f68a90>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f6af50>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f69a50>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f68c90>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f688d0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f68510>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f68f90>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f686d0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f6b350>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f6a510>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f68a50>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f68310>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f6ba50>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f6b010>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f6a3d0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f68650>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f6ba90>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f6a5d0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f6a490>],\n",
       "  '1000-2000': [<sentence_transformers.readers.InputExample.InputExample at 0x307f69e90>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f6aed0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f69210>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f690d0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f6a750>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f68710>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f6a390>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f68e50>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f68150>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f6b3d0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f69850>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f68e10>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f69f50>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f69950>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f682d0>,\n",
       "   <sentence_transformers.readers.InputExample.InputExample at 0x307f6a150>]}}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluators = {}\n",
    "\n",
    "for subset in SUBSETS:\n",
    "    evaluators_subset = {}\n",
    "    samples_subset = samples[subset]\n",
    "    for i in range(len(BINS)-1):\n",
    "        key = f\"{BINS[i]}-{BINS[i+1]}\"\n",
    "        evaluators_subset[key] = EmbeddingSimilarityEvaluator.from_input_examples(samples_subset[key], name=f\"sts22-{key}\")\n",
    "    evaluators[subset] = evaluators_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': {'0-200': <sentence_transformers.evaluation.EmbeddingSimilarityEvaluator.EmbeddingSimilarityEvaluator at 0x307f6bbd0>,\n",
       "  '200-400': <sentence_transformers.evaluation.EmbeddingSimilarityEvaluator.EmbeddingSimilarityEvaluator at 0x307f6bb90>,\n",
       "  '400-1000': <sentence_transformers.evaluation.EmbeddingSimilarityEvaluator.EmbeddingSimilarityEvaluator at 0x307f69650>,\n",
       "  '1000-2000': <sentence_transformers.evaluation.EmbeddingSimilarityEvaluator.EmbeddingSimilarityEvaluator at 0x307f69910>}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model sentence-transformers/gtr-t5-large\n",
      "Evaluating subset en\n",
      "Evaluating bin 0-200\n",
      "Evaluating bin 200-400\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results/sts22-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(output_path, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mevaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/sentence_transformers/evaluation/EmbeddingSimilarityEvaluator.py:77\u001b[0m, in \u001b[0;36mEmbeddingSimilarityEvaluator.__call__\u001b[0;34m(self, model, output_path, epoch, steps)\u001b[0m\n\u001b[1;32m     73\u001b[0m     out_txt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbeddingSimilarityEvaluator: Evaluating the model on \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m out_txt)\n\u001b[0;32m---> 77\u001b[0m embeddings1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msentences1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m embeddings2 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentences2, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow_progress_bar, convert_to_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     79\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscores\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:165\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    162\u001b[0m features \u001b[38;5;241m=\u001b[39m batch_to_device(features, device)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 165\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_value \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    168\u001b[0m         embeddings \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/sentence_transformers/models/Transformer.py:66\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m     64\u001b[0m     trans_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 66\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     69\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m'\u001b[39m: output_tokens, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m: features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]})\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:1978\u001b[0m, in \u001b[0;36mT5EncoderModel.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1961\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[1;32m   1962\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1974\u001b[0m \u001b[38;5;124;03m>>> last_hidden_states = outputs.last_hidden_state\u001b[39;00m\n\u001b[1;32m   1975\u001b[0m \u001b[38;5;124;03m```\"\"\"\u001b[39;00m\n\u001b[1;32m   1976\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1978\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1979\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1981\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1983\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1984\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1985\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1988\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m encoder_outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:1113\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1099\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39mforward,\n\u001b[1;32m   1100\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         output_attentions,\n\u001b[1;32m   1111\u001b[0m     )\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1113\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:694\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    692\u001b[0m     self_attn_past_key_value, cross_attn_past_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m hidden_states, present_key_value_state \u001b[38;5;241m=\u001b[39m self_attention_outputs[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    704\u001b[0m attention_outputs \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m2\u001b[39m:]  \u001b[38;5;66;03m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:601\u001b[0m, in \u001b[0;36mT5LayerSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    592\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    598\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    599\u001b[0m ):\n\u001b[1;32m    600\u001b[0m     normed_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 601\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSelfAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormed_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_output[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    611\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (hidden_states,) \u001b[38;5;241m+\u001b[39m attention_output[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:572\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m layer_head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    570\u001b[0m     attn_weights \u001b[38;5;241m=\u001b[39m attn_weights \u001b[38;5;241m*\u001b[39m layer_head_mask\n\u001b[0;32m--> 572\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m unshape(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# (batch_size, seq_length, dim)\u001b[39;00m\n\u001b[1;32m    573\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mo(attn_output)\n\u001b[1;32m    575\u001b[0m present_key_value_state \u001b[38;5;241m=\u001b[39m (key_states, value_states) \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder \u001b[38;5;129;01mand\u001b[39;00m use_cache) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models = [\n",
    "  \"sentence-transformers/gtr-t5-large\"\n",
    "]\n",
    "\n",
    "for model_name in models:\n",
    "  print(\"Evaluating model\", model_name)\n",
    "  model = SentenceTransformer(model_name)\n",
    "  for subset in evaluators:\n",
    "    print(\"Evaluating subset\", subset)\n",
    "    evaluators_subset = evaluators[subset]\n",
    "    for key in evaluators_subset:\n",
    "      print(\"Evaluating bin\", key)\n",
    "      evaluator = evaluators_subset[key]\n",
    "      output_path = f\"./results/sts22-{subset}/{model_name}/\"\n",
    "      os.makedirs(output_path, exist_ok=True)\n",
    "      evaluator(model, output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Range  Cosine_Pearson  Sample Count\n",
      "0      0-200        0.496388            38\n",
      "1    200-400        0.760514            72\n",
      "2   400-1000        0.614951            70\n",
      "3  1000-2000        0.512712            16\n"
     ]
    }
   ],
   "source": [
    "for model_name in models:\n",
    "  for subset in evaluators:\n",
    "    file_paths = []\n",
    "    extracted_data = {'Range': [], 'Cosine_Pearson': [], 'Sample Count': []}\n",
    "    for key in evaluators[subset]:\n",
    "      file_path = f\"./results/sts22-{subset}/{model_name}/similarity_evaluation_sts22-{key}_results.csv\"\n",
    "      file_paths.append(file_path)\n",
    "\n",
    "      df = pd.read_csv(file_path)\n",
    "      cosine_pearson = df['cosine_pearson'].mean()\n",
    "      extracted_data['Range'].append(key)\n",
    "      extracted_data['Cosine_Pearson'].append(cosine_pearson)\n",
    "      extracted_data['Sample Count'].append(len(samples[subset][key]))\n",
    "    extracted_df = pd.DataFrame(extracted_data)\n",
    "    print(extracted_df) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

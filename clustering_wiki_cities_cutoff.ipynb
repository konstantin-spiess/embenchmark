{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering - Split Dataset by sentence length\n",
    "**Task**: Take a clustering dataset, split it into multiple datasets based on the length of the sentences and benchmark the performance of a clustering algorithm on each of the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (1.0.1)\n",
      "Requirement already satisfied: datasets in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (2.14.6)\n",
      "Requirement already satisfied: transformers in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (4.37.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from datasets) (1.26.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from datasets) (14.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from datasets) (2.1.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from datasets) (0.20.3)\n",
      "Requirement already satisfied: packaging in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: filelock in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from aiohttp->datasets) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/malte/miniconda3/envs/embenchmark2/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv datasets transformers scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "if(load_dotenv(\".env\") == False):\n",
    "    print(\"No .env file found\")\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModel\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import sklearn\n",
    "import sklearn.cluster\n",
    "\n",
    "# if path exists at all: \"/Users/malte\", add the mteb package to the path\n",
    "\n",
    "if os.path.exists('/Users/malte'):\n",
    "    sys.path.append('/Users/malte/Developer/embenchmark/packages/mteb')\n",
    "    from packages.mteb.mteb.evaluation.evaluators import ClusteringEvaluator\n",
    "else:\n",
    "    from mteb import ClusteringEvaluator\n",
    "\n",
    "\n",
    "# model = AutoModel.from_pretrained('jinaai/jina-embeddings-v2-base-en', trust_remote_code=True ).to('mps')\n",
    "model = SentenceTransformer('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.28224272e-01, -2.25861192e-01,  7.68644392e-01,  2.89305389e-01,\n",
       "       -8.69723782e-02,  3.44936848e-02,  1.31829679e-01, -4.00960654e-01,\n",
       "        8.21037531e-01,  5.30947685e-01, -2.93557078e-01, -3.56913507e-01,\n",
       "       -3.13871861e-01,  4.35310364e-01, -2.39897579e-01,  7.03264832e-01,\n",
       "       -3.18590045e-01,  3.89612287e-01,  2.71432132e-01, -4.44263190e-01,\n",
       "       -4.64006513e-01, -5.17209589e-01, -5.75835466e-01, -6.02083579e-02,\n",
       "        3.43666524e-01,  6.86448634e-01,  3.84453565e-01,  1.87769353e-01,\n",
       "        1.68828383e-01,  5.26927471e-01, -1.38831794e-01,  4.03478205e-01,\n",
       "       -3.10320884e-01,  2.10948989e-01, -3.50877702e-01, -5.76881826e-01,\n",
       "       -3.28562334e-02,  2.18825892e-01,  7.21675873e-01,  6.78117752e-01,\n",
       "        3.10788900e-01,  1.31032988e-01,  1.62814651e-02,  1.06907332e+00,\n",
       "       -2.67281920e-01,  1.65431350e-01, -2.30780542e-01, -2.73894779e-02,\n",
       "       -1.04981318e-01, -4.30489898e-01, -3.76143038e-01, -7.55695581e-01,\n",
       "       -2.73756627e-02, -8.73075902e-01, -1.37955754e-03,  4.84690785e-01,\n",
       "        1.07242155e+00,  7.36877769e-02, -2.56212145e-01, -4.11943138e-01,\n",
       "       -5.46480060e-01,  9.94578123e-01, -7.25141108e-01,  4.05226201e-01,\n",
       "        2.00599581e-01, -1.47248060e-01, -4.29521114e-01, -6.74018919e-01,\n",
       "       -6.66123450e-01, -2.19339982e-01, -6.46834970e-01,  4.19914275e-01,\n",
       "       -8.05839524e-02, -4.94235337e-01,  4.38127935e-01,  5.83130836e-01,\n",
       "       -8.47906053e-01, -4.08034086e-01, -6.16970599e-01,  1.34927168e-01,\n",
       "        3.69782776e-01,  1.34458467e-01,  2.49960288e-01,  1.60312682e-01,\n",
       "       -8.53928924e-01, -4.08455078e-03, -5.81825912e-01,  3.07522207e-01,\n",
       "        3.57922405e-01, -2.19832823e-01, -3.36791009e-01,  6.89992309e-01,\n",
       "       -1.66281685e-01,  2.42417574e-01,  3.25396627e-01,  1.14751980e-01,\n",
       "        2.78772295e-01, -4.89124924e-01, -1.56913355e-01, -2.16250435e-01,\n",
       "        6.98147774e-01,  7.80305028e-01,  1.91614226e-01, -1.92275718e-01,\n",
       "        1.16618671e-01, -8.62285718e-02,  4.76528443e-02, -6.59651577e-01,\n",
       "       -1.70873702e-01,  3.57272655e-01, -1.88011140e-01,  1.44169390e-01,\n",
       "        6.32560074e-01, -7.18434930e-01, -1.45201072e-01,  2.46995375e-01,\n",
       "        1.28379434e-01, -5.36232591e-01,  2.66003430e-01,  1.66335762e-01,\n",
       "       -3.66975009e-01,  3.51706594e-01,  2.30230838e-01, -9.00376260e-01,\n",
       "        4.86030489e-01,  3.72996151e-01,  6.37244582e-01, -1.65294498e-01,\n",
       "       -2.80620217e-01, -2.80249089e-01,  6.20775044e-01, -4.76410776e-01,\n",
       "        6.07419312e-01, -2.15708554e-01, -3.34222525e-01, -2.20921293e-01,\n",
       "        7.03401566e-01, -3.96388054e-01, -5.16963482e-01,  1.02488732e+00,\n",
       "       -1.30751699e-01,  2.85910457e-01, -3.91239375e-01, -7.17176139e-01,\n",
       "       -5.81076145e-01, -9.82339978e-02, -3.58501256e-01,  7.35219598e-01,\n",
       "        1.43784225e-01, -1.16845560e+00,  1.76820099e-01, -6.28405690e-01,\n",
       "       -3.77321064e-01,  2.75222361e-01, -2.79936761e-01, -1.78136155e-01,\n",
       "        1.68924898e-01, -6.50280043e-02,  2.76211321e-01, -4.41197991e-01,\n",
       "       -5.31367481e-01,  1.00446679e-01, -2.49667734e-01,  8.95122647e-01,\n",
       "       -4.15973999e-02,  1.05265343e+00,  5.23014247e-01, -5.15321791e-01,\n",
       "       -5.33773340e-02, -2.56199509e-01,  1.97630897e-01,  3.12006563e-01,\n",
       "       -3.01622689e-01, -3.65368634e-01, -1.00672901e-01, -3.27127784e-01,\n",
       "        1.35327838e-02,  3.26976210e-01, -9.09752786e-01,  2.16267407e-01,\n",
       "       -5.57309389e-01,  7.23839402e-01,  8.92173231e-01,  5.43989003e-01,\n",
       "        5.57780087e-01, -1.03427005e+00,  1.93832040e-01,  9.38819572e-02,\n",
       "       -8.27748403e-02,  4.55609709e-01, -5.03936887e-01, -1.22847235e+00,\n",
       "       -1.89527288e-01, -6.98606446e-02,  1.05925012e+00, -5.24091005e-01,\n",
       "        4.51738238e-01, -1.84631974e-01, -7.72590220e-01, -3.19510698e-01,\n",
       "       -5.69767784e-03,  2.94253141e-01,  2.50187367e-01,  1.41633347e-01,\n",
       "       -1.77425742e-01, -4.81416553e-01, -7.22434342e-01, -5.10600924e-01,\n",
       "       -3.86191249e-01, -9.04626548e-02,  7.23022163e-01,  8.53163123e-01,\n",
       "        1.76970497e-01,  4.05392796e-01, -7.57191777e-01, -4.31815237e-01,\n",
       "       -2.38153636e-01, -6.61354810e-02,  9.78687763e-01,  6.61362827e-01,\n",
       "        1.03492653e+00, -1.03738499e+00, -8.96692753e-01,  8.16100240e-02,\n",
       "       -6.99178576e-01, -2.20789880e-01, -1.89682841e-01, -1.83055982e-01,\n",
       "       -7.98380896e-02,  1.91821992e-01, -4.45958287e-01,  5.66622615e-01,\n",
       "        1.33619249e-01, -8.05341780e-01,  4.66850698e-01, -5.26848078e-01,\n",
       "        6.54413521e-01, -1.06482553e+00,  5.13969548e-03, -2.43212208e-01,\n",
       "       -1.16571344e-01, -3.91471833e-01, -1.37884423e-01, -2.22038031e-01,\n",
       "        2.38618985e-01, -9.15466607e-01,  9.96800601e-01, -9.05895352e-01,\n",
       "        3.60051930e-01,  1.78796113e-01,  6.41813129e-02,  2.02188388e-01,\n",
       "        3.42299908e-01,  1.08137745e-02,  8.06761324e-01,  5.96215665e-01,\n",
       "       -7.12887049e-01,  6.70213938e-01,  2.56319076e-01, -1.86432391e-01,\n",
       "        7.64364660e-01, -6.20776474e-01, -2.13098288e-01, -5.01361974e-02,\n",
       "        1.08501822e-01, -1.66708529e+00, -3.87686372e-01,  6.75168872e-01,\n",
       "       -6.62894666e-01, -1.38809249e-01,  3.62190038e-01, -4.01225835e-01,\n",
       "       -8.01215827e-01, -4.66251791e-01,  1.46596611e-01,  1.80920437e-01,\n",
       "       -2.17988133e-01,  3.58722478e-01,  1.82566687e-01, -1.66851968e-01,\n",
       "       -6.02780700e-01, -9.81439650e-01, -3.78241122e-01, -3.96559566e-01,\n",
       "       -6.88403904e-01,  2.47284770e-01, -6.08096123e-01, -5.48775554e-01,\n",
       "       -1.55308634e-01, -4.40574884e-01, -4.12821025e-01,  5.83611615e-02,\n",
       "        6.18661880e-01, -3.24897990e-02, -4.44587506e-02, -2.33671218e-01,\n",
       "       -1.58341587e-01, -1.43569991e-01, -4.46259789e-03,  4.76977043e-02,\n",
       "        5.48889756e-01, -4.22232747e-01, -2.35057235e-01, -7.05350935e-01,\n",
       "        8.36965442e-01,  8.21019292e-01,  2.60429624e-02,  6.28794372e-01,\n",
       "        4.52745825e-01,  7.89286569e-02,  8.13911110e-02, -7.64958322e-01,\n",
       "       -1.44860506e-01, -4.71618831e-01, -4.16214019e-01, -2.50047088e-01,\n",
       "       -6.58569396e-01,  6.38350427e-01, -2.55747493e-02,  3.24409127e-01,\n",
       "        8.06686223e-01,  6.00031793e-01, -6.79434776e-01,  4.22212541e-01,\n",
       "        2.96182036e-01,  2.10553393e-01,  2.73180813e-01, -6.51915073e-01,\n",
       "        2.18717813e-01, -7.47442484e-01, -1.93855092e-01, -6.17749333e-01,\n",
       "       -5.97563207e-01, -2.65895337e-01, -6.31573617e-01,  4.46480155e-01,\n",
       "       -1.57283828e-01, -1.06426552e-01,  3.88524652e-01, -5.56058288e-01,\n",
       "        4.95253175e-01,  3.29326272e-01,  3.39435749e-02,  2.52846509e-01,\n",
       "       -4.12106007e-01, -6.06908083e-01, -1.39256522e-01, -4.79529262e-01,\n",
       "       -6.57987058e-01,  8.12867761e-01,  3.81229550e-01,  9.84920442e-01,\n",
       "        4.77192074e-01,  6.79150283e-01,  3.00378948e-01,  2.94085592e-01,\n",
       "       -5.89630067e-01,  8.51289332e-01,  3.11070997e-02, -1.03311491e+00,\n",
       "       -2.95036465e-01, -3.11165601e-01, -1.04611039e+00,  9.77494717e-02,\n",
       "       -1.22390427e-01, -7.49685884e-01,  4.98734444e-01, -3.30004424e-01,\n",
       "       -8.62102330e-01,  4.93798971e-01, -9.58635330e-01,  9.32269692e-01,\n",
       "       -5.38495719e-01, -6.86450779e-01,  2.74521977e-01, -9.10801947e-01,\n",
       "        3.23433965e-01,  5.11773765e-01,  2.72645682e-01, -1.83054492e-01,\n",
       "       -3.12111080e-01,  1.06015062e+00, -7.00693309e-01,  6.29035652e-01,\n",
       "        2.38332614e-01,  2.71469206e-01,  5.13505518e-01,  1.07971124e-01,\n",
       "        3.05834830e-01,  5.88502169e-01,  3.97365279e-02, -7.37241581e-02,\n",
       "        2.87974834e-01, -3.85834187e-01, -1.78592429e-01,  9.32006955e-01,\n",
       "       -7.54035711e-01, -4.83758628e-01, -1.16973460e+00, -1.91871360e-01,\n",
       "        3.59545708e-01,  1.65212288e-01,  6.49903297e-01,  1.38343312e-02,\n",
       "       -2.56621003e-01,  6.03065073e-01,  5.58669448e-01, -4.78544980e-02,\n",
       "        7.36810148e-01,  7.38783479e-01, -7.56350458e-02, -6.18333519e-01,\n",
       "        6.06378973e-01,  3.43404710e-01,  8.78352858e-03,  4.91299272e-01,\n",
       "        9.52867568e-02, -1.77292690e-01, -2.97967255e-01, -2.52462059e-01,\n",
       "        5.17572820e-01, -3.12638700e-01, -1.84084460e-01, -7.78754413e-01,\n",
       "       -2.76753545e-01, -7.29530931e-01, -5.87049365e-01, -4.15948004e-01,\n",
       "       -2.86790073e-01, -4.82183427e-01, -9.41365808e-02,  3.66355538e-01,\n",
       "        8.07880700e-01, -4.54039842e-01,  4.33065832e-01, -5.70147574e-01,\n",
       "        3.77654105e-01,  1.84492230e-01, -4.00126353e-02, -3.32712322e-01,\n",
       "       -3.91168803e-01, -4.83407192e-02, -4.96013612e-02, -3.02106917e-01,\n",
       "       -1.48895741e+00,  7.71931231e-01, -1.21690661e-01,  6.10107958e-01,\n",
       "        4.23115313e-01,  1.70163035e-01,  3.48084062e-01, -2.69301027e-01,\n",
       "        9.73516643e-01,  2.83442557e-01, -6.15788817e-01,  2.19903708e-01,\n",
       "       -2.47952804e-01, -2.07082092e-04,  6.14836335e-01,  7.60569274e-01,\n",
       "       -6.83239043e-01, -4.64457452e-01, -5.63625455e-01, -9.85854685e-01,\n",
       "        3.30225468e-01,  4.00010675e-01, -9.15097445e-02, -4.31424141e-01,\n",
       "       -6.09092414e-02,  1.02170184e-01, -1.49348145e-02, -1.02801716e+00,\n",
       "       -8.09639454e-01,  1.28955260e-01,  4.30038810e-01,  7.28237256e-02,\n",
       "       -2.60610789e-01, -4.92932051e-01, -9.12082851e-01,  9.00085568e-01,\n",
       "        7.70274460e-01,  1.14934109e-01,  6.08134508e-01, -4.54742610e-02,\n",
       "       -1.18666003e-02,  7.06058264e-01,  8.53359699e-01,  8.31942320e-01,\n",
       "       -3.50042135e-01,  4.13785100e-01,  3.18333805e-01, -6.49656475e-01,\n",
       "        5.33586502e-01, -2.71508962e-01, -1.75757736e-01,  3.25279564e-01,\n",
       "       -2.07633734e-01,  5.93657970e-01,  3.48928958e-01, -3.80440682e-01,\n",
       "        5.37197292e-01, -4.83318835e-01, -1.91197619e-01, -1.14510918e+00,\n",
       "       -5.06426319e-02,  1.14719570e-01,  3.59266311e-01,  5.67747593e-01,\n",
       "       -1.20422440e-02, -1.58963948e-01, -6.05251372e-01,  2.65052885e-01,\n",
       "        4.07733142e-01, -2.43907094e-01,  1.00121662e-01,  8.43749881e-01,\n",
       "        3.65785778e-01, -1.80001464e-02,  2.66359389e-01, -4.05661672e-01,\n",
       "       -5.17035782e-01,  3.73387605e-01,  6.68582380e-01,  7.16597497e-01,\n",
       "       -6.93563759e-01,  2.49034196e-01,  7.20508575e-01,  2.46196270e-01,\n",
       "        2.49970481e-01,  8.51470411e-01,  3.48573059e-01, -4.06547904e-01,\n",
       "        2.30746288e-02, -7.95286536e-01, -2.20218271e-01,  2.96165615e-01,\n",
       "       -2.12248147e-01, -1.72320560e-01, -6.66743338e-01, -2.11628109e-01,\n",
       "       -1.65353701e-01,  1.67293310e-01, -5.28563619e-01,  7.19288588e-02,\n",
       "       -1.04418732e-01,  5.96273780e-01, -1.14276493e+00,  6.36181533e-01,\n",
       "        7.82059789e-01, -5.17990768e-01, -8.11072707e-01, -8.39691833e-02,\n",
       "       -1.84083521e-01, -5.01284122e-01,  5.91768026e-01, -2.63654649e-01,\n",
       "       -6.82049543e-02, -2.14423016e-02, -6.75572693e-01, -9.54332650e-01,\n",
       "        9.62322056e-01,  1.18673734e-01, -2.97195703e-01,  1.51859283e-01,\n",
       "       -9.66130495e-02,  3.34252179e-01, -4.47160363e-01,  4.74396825e-01,\n",
       "        4.59647387e-01,  9.30253088e-01,  4.92698550e-01, -4.86736983e-01,\n",
       "        6.76306784e-02, -2.11406574e-01, -4.71383929e-01, -1.35266319e-01,\n",
       "       -9.14632142e-01,  1.42242455e+00, -4.56210107e-01, -2.90909141e-01,\n",
       "        4.70298469e-01,  9.68084753e-01, -1.83871359e-01,  4.24463674e-02,\n",
       "        3.48587304e-01,  9.55314100e-01,  5.86955070e-01, -1.64082944e-01,\n",
       "        8.93286288e-01, -1.28982782e-01,  7.58353695e-02,  7.54073620e-01,\n",
       "       -1.39584824e-01,  7.30853021e-01,  9.09658849e-01, -3.31373781e-01,\n",
       "        3.75825077e-01,  7.00301051e-01,  9.01738629e-02,  4.90855396e-01,\n",
       "        3.98591876e-01, -5.08095562e-01, -1.11744821e-01, -2.12775379e-01,\n",
       "       -5.60423374e-01,  4.66721684e-01,  3.85874301e-01, -6.55571461e-01,\n",
       "       -1.29477754e-02, -1.78936735e-01,  5.61587572e-01,  5.84997907e-02,\n",
       "       -1.39338076e-01,  5.80574334e-01,  2.40131259e-01, -6.66644275e-01,\n",
       "        1.01033080e+00, -4.44661140e-01,  3.23399544e-01, -5.30080974e-01,\n",
       "       -1.40003756e-01, -3.98562968e-01,  1.93391696e-01, -2.68618941e-01,\n",
       "       -1.01054192e+00,  2.10861742e-01, -2.45114297e-01, -2.67073691e-01,\n",
       "       -3.50066006e-01,  3.24706197e-01, -3.19272697e-01, -7.15011656e-01,\n",
       "        3.33335638e-01,  5.69951832e-01,  7.56881654e-01,  2.72665322e-01,\n",
       "       -4.51972038e-01, -1.72901273e-01,  1.75510302e-01, -2.83093005e-01,\n",
       "        1.04845896e-01,  2.90563732e-01,  4.27015334e-01,  3.00923198e-01,\n",
       "        5.05698204e-01,  4.02983129e-01,  3.07944179e-01, -6.06513143e-01,\n",
       "        6.64225936e-01, -6.24953032e-01, -2.69902974e-01, -9.70961034e-01,\n",
       "        5.57277918e-01, -2.34654769e-01, -2.92361736e-01,  9.00345027e-01,\n",
       "        8.14971626e-01,  8.40940535e-01, -4.87698674e-01,  7.10541964e-01,\n",
       "       -3.38917494e-01,  9.37312901e-01, -3.60095859e-01,  9.52106297e-01,\n",
       "       -8.72870505e-01, -2.20545799e-01, -3.05119693e-01, -1.14262116e+00,\n",
       "       -1.24789476e-02,  8.18798065e-01, -7.41380930e-01, -2.85720080e-01,\n",
       "        1.33268332e+00,  5.25803626e-01, -3.69302705e-02, -2.07680017e-01,\n",
       "        3.03433329e-01,  8.71080816e-01, -9.17263776e-02,  8.98449421e-01,\n",
       "        7.47316420e-01, -4.16250974e-01,  2.54360318e-01, -2.75751501e-01,\n",
       "       -1.36254489e-01, -5.12495935e-01, -6.79533780e-01, -4.82197821e-01,\n",
       "       -6.33957088e-01, -5.63278683e-02, -2.75773078e-01,  8.25538486e-02,\n",
       "        8.92717123e-01,  1.83944136e-01, -1.08761716e+00, -6.10184193e-01,\n",
       "        4.65343714e-01,  4.19319153e-01, -4.94443178e-01, -2.53033996e-01,\n",
       "        2.37810254e-01,  1.62645996e-01, -6.58877552e-01,  5.10205030e-01,\n",
       "        3.88456374e-01,  3.75556916e-01,  2.24154383e-01, -1.26673490e-01,\n",
       "       -8.16800177e-01,  3.19146603e-01,  2.35014766e-01,  7.16929018e-01,\n",
       "       -7.36250341e-01, -4.04545844e-01, -1.80296361e-01, -5.60725868e-01,\n",
       "        2.15711504e-01,  4.83404189e-01, -2.68410265e-01,  1.94057405e-01,\n",
       "        9.00214672e-01,  1.09127900e-02,  4.99017328e-01,  1.81332827e-01,\n",
       "        3.67436737e-01, -5.41105688e-01,  5.10594785e-01,  6.48476720e-01,\n",
       "        7.06440687e-01, -6.35155439e-02, -3.16842824e-01,  9.60462511e-01,\n",
       "        4.45953965e-01, -8.65428090e-01, -6.23088598e-01,  1.41711771e-01,\n",
       "       -1.59554076e+00, -1.08424380e-01,  1.16096830e+00, -5.22535682e-01,\n",
       "       -4.15220380e-01, -1.15004249e-01, -4.92485613e-01,  4.77262557e-01,\n",
       "       -4.26036119e-01,  1.49858072e-01,  7.62583494e-01, -3.58477831e-01,\n",
       "        1.75336227e-01, -1.30188334e+00,  3.71742755e-01,  5.58143556e-01,\n",
       "       -7.14728594e-01,  1.87094212e-01,  4.36377108e-01,  5.00331998e-01,\n",
       "        2.42126286e-01,  9.12749887e-01, -3.94961946e-02,  2.70841625e-02,\n",
       "       -3.09471935e-01, -2.16769688e-02,  4.82023597e-01, -2.04955161e-01,\n",
       "        5.31031966e-01, -2.74190679e-02, -1.29281551e-01, -4.34279650e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encode(\"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aliquam hendrerit non libero at egestas. Nunc aliquam iaculis orci id lacinia. Nam ac urna congue, dapibus felis ut, condimentum leo. In libero metus, varius nec ultricies at, mattis eget ex. Nam tincidunt rhoncus pretium. Nam quis placerat felis. Donec convallis ante ac euismod pretium. Aliquam magna arcu, tempor et lorem ut, dictum posuere metus. Donec gravida aliquet laoreet. Sed ac massa dolor. Donec tincidunt sem in est ultrices fermentum. Sed in consequat ante, in faucibus urna. Donec iaculis bibendum ipsum, non dapibus urna consequat quis. Aenean eu fringilla libero. Nam egestas lorem leo, id varius risus ultricies id. Nulla in elit tellus. Aliquam hendrerit placerat fringilla. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Nulla facilisi. Integer egestas maximus mi non aliquet. Morbi et tempus urna. Integer volutpat dolor et lorem suscipit, ac ullamcorper ligula elementum. Proin accumsan, sapien sed euismod tempus, quam odio maximus dui, nec lacinia magna nisi vel erat. Donec odio justo, pretium in euismod eu, luctus sit amet nisl. Curabitur sollicitudin, dui vitae venenatis varius, odio sapien dictum arcu, et tincidunt metus eros vitae augue. Sed vel magna ut quam porta interdum. Sed vitae nibh lectus. Vivamus felis turpis, bibendum vel congue in, tristique a ante. Ut leo nisl, ultrices at porttitor eu, ullamcorper id sapien. Praesent molestie, nisl in condimentum auctor, mi sapien interdum odio, a mattis risus ligula nec mi. Fusce consequat ante lorem, id cursus libero facilisis in. Ut nec risus lorem. In pharetra justo eget odio placerat posuere. Nam vel nisl ipsum. Donec ut posuere tortor. Maecenas id enim blandit, pellentesque sem nec, tincidunt dolor. Aliquam consectetur mauris nec nisi volutpat luctus. Nunc tempus dui magna, quis porttitor quam ultrices vitae. Praesent eu mi blandit felis bibendum egestas sit amet non quam. Cras aliquam ultricies tortor id laoreet. Quisque risus augue, accumsan quis vulputate id, vestibulum et dolor. Praesent nulla purus, aliquet vitae orci sit amet, consequat auctor turpis. Duis rhoncus pharetra justo non vehicula. Integer vestibulum iaculis vestibulum. Donec condimentum, purus eu porta blandit, elit ante aliquam lectus, non ultricies felis dolor eu libero. Duis elementum massa quam, sit amet dignissim est malesuada dapibus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"jinaai/cities_wiki_clustering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator(sentences, labels, model, max_length=512, batch_size=1, clustering_batch_size=500):\n",
    "    # cut sentences to max_length * 2 words to avoid OOM\n",
    "    sentences = [s[:len(s.split()) * 2] for s in sentences]\n",
    "    \n",
    "    corpus_embeddings = np.asarray(model.encode(sentences, batch_size=batch_size, max_length=max_length))\n",
    "\n",
    "    clustering_model = sklearn.cluster.MiniBatchKMeans(\n",
    "        n_clusters=len(set(labels)), batch_size=clustering_batch_size, n_init=\"auto\"\n",
    "    )\n",
    "    clustering_model.fit(corpus_embeddings)\n",
    "\n",
    "    cluster_assignment = clustering_model.labels_\n",
    "\n",
    "    v_measure = sklearn.metrics.cluster.v_measure_score(labels, cluster_assignment)\n",
    "\n",
    "    return {\"v_measure\": v_measure}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataset, max_length=512, split=\"test\", **kwargs):\n",
    "    v_measures = []\n",
    "    for cluster_set in tqdm.tqdm(dataset[split], desc=\"Clustering\"):\n",
    "        metrics = evaluator(cluster_set[\"sentences\"], cluster_set[\"labels\"], model, max_length=max_length)\n",
    "        v_measures.append(metrics[\"v_measure\"])\n",
    "\n",
    "    v_mean = np.mean(v_measures)\n",
    "    v_std = np.std(v_measures)\n",
    "    return {\"v_measure\": v_mean, \"v_measure_std\": v_std}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"text\", data_files={\"train\": [\"test.jsonl.gz\"]})\n",
    "# get keys of dataset[\"train\"][0]\n",
    "dataset[\"train\"][0]['text']\n",
    "\n",
    "# parse dataset[\"train\"][0]['text'] json string\n",
    "import json\n",
    "decoded = json.loads(dataset[\"train\"][0]['text'])\n",
    "\n",
    "sentences, labels = decoded[\"sentences\"], decoded[\"labels\"]\n",
    "\n",
    "# limit to 60 samples\n",
    "sentences, labels = sentences[:60], labels[:60]\n",
    "\n",
    "# split into three parts\n",
    "n = len(sentences)\n",
    "n1 = n // 3\n",
    "\n",
    "sentences1, sentences2, sentences3 = sentences[:n1], sentences[n1:2*n1], sentences[2*n1:]\n",
    "labels1, labels2, labels3 = labels[:n1], labels[n1:2*n1], labels[2*n1:]\n",
    "\n",
    "ds = [{\n",
    "    \"sentences\": sentences1,\n",
    "    \"labels\": labels1\n",
    "}, {\n",
    "    \"sentences\": sentences2,\n",
    "    \"labels\": labels2\n",
    "}, {\n",
    "    \"sentences\": sentences3,\n",
    "    \"labels\": labels3\n",
    "}]\n",
    "\n",
    "\n",
    "\n",
    "# create new dataset from decoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clustering:   0%|          | 0/1 [00:17<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m max_lengths \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m2000\u001b[39m, \u001b[38;5;241m5000\u001b[39m, \u001b[38;5;241m8192\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m max_length \u001b[38;5;129;01min\u001b[39;00m max_lengths:\n\u001b[0;32m----> 4\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m   \u001b[38;5;28mprint\u001b[39m(max_length, result)\n\u001b[1;32m      6\u001b[0m   \u001b[38;5;66;03m# append line to file\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, dataset, max_length, split, **kwargs)\u001b[0m\n\u001b[1;32m      2\u001b[0m v_measures \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cluster_set \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(dataset[split], desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClustering\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcluster_set\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msentences\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcluster_set\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     v_measures\u001b[38;5;241m.\u001b[39mappend(metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv_measure\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      7\u001b[0m v_mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(v_measures)\n",
      "Cell \u001b[0;32mIn[19], line 5\u001b[0m, in \u001b[0;36mevaluator\u001b[0;34m(sentences, labels, model, max_length, batch_size, clustering_batch_size)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluator\u001b[39m(sentences, labels, model, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, clustering_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# cut sentences to max_length * 2 words to avoid OOM\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [s[:\u001b[38;5;28mlen\u001b[39m(s\u001b[38;5;241m.\u001b[39msplit()) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m sentences]\n\u001b[0;32m----> 5\u001b[0m     corpus_embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      7\u001b[0m     clustering_model \u001b[38;5;241m=\u001b[39m sklearn\u001b[38;5;241m.\u001b[39mcluster\u001b[38;5;241m.\u001b[39mMiniBatchKMeans(\n\u001b[1;32m      8\u001b[0m         n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(labels)), batch_size\u001b[38;5;241m=\u001b[39mclustering_batch_size, n_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m     )\n\u001b[1;32m     10\u001b[0m     clustering_model\u001b[38;5;241m.\u001b[39mfit(corpus_embeddings)\n",
      "File \u001b[0;32m~/miniconda3/envs/embenchmark2/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/jinaai/jina-bert-implementation/c41d17d28431712f4b24b52bb83d426d7137a02f/modeling_bert.py:1222\u001b[0m, in \u001b[0;36mJinaBertModel.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **tokenizer_kwargs)\u001b[0m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m range_iter:\n\u001b[1;32m   1217\u001b[0m     encoded_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(\n\u001b[1;32m   1218\u001b[0m         sentences[i : i \u001b[38;5;241m+\u001b[39m batch_size],\n\u001b[1;32m   1219\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1220\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtokenizer_kwargs,\n\u001b[1;32m   1221\u001b[0m     )\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1222\u001b[0m     token_embs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mencoded_input\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1224\u001b[0m     \u001b[38;5;66;03m# Accumulate in fp32 to avoid overflow\u001b[39;00m\n\u001b[1;32m   1225\u001b[0m     token_embs \u001b[38;5;241m=\u001b[39m token_embs\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/jinaai/jina-bert-implementation/c41d17d28431712f4b24b52bb83d426d7137a02f/modeling_bert.py:1417\u001b[0m, in \u001b[0;36mJinaBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1408\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1410\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m   1411\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1412\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1415\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1416\u001b[0m )\n\u001b[0;32m-> 1417\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1418\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1419\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1424\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1425\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1426\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1428\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1429\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1430\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1431\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1432\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/embenchmark2/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/embenchmark2/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/jinaai/jina-bert-implementation/c41d17d28431712f4b24b52bb83d426d7137a02f/modeling_bert.py:822\u001b[0m, in \u001b[0;36mJinaBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    812\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    813\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    814\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    819\u001b[0m         alibi_bias,\n\u001b[1;32m    820\u001b[0m     )\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 822\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43malibi_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/envs/embenchmark2/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/embenchmark2/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/jinaai/jina-bert-implementation/c41d17d28431712f4b24b52bb83d426d7137a02f/modeling_bert.py:619\u001b[0m, in \u001b[0;36mJinaBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, bias, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    606\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    614\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    616\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    617\u001b[0m         past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     )\n\u001b[0;32m--> 619\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    627\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/embenchmark2/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/embenchmark2/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/jinaai/jina-bert-implementation/c41d17d28431712f4b24b52bb83d426d7137a02f/modeling_bert.py:509\u001b[0m, in \u001b[0;36mJinaBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions, bias)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    490\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    497\u001b[0m     bias: Optional[torch\u001b[38;5;241m.\u001b[39mFloatTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    498\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    499\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself(\n\u001b[1;32m    500\u001b[0m         hidden_states,\n\u001b[1;32m    501\u001b[0m         attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    507\u001b[0m         bias,\n\u001b[1;32m    508\u001b[0m     )\n\u001b[0;32m--> 509\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    512\u001b[0m     ]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/embenchmark2/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/embenchmark2/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/jinaai/jina-bert-implementation/c41d17d28431712f4b24b52bb83d426d7137a02f/modeling_bert.py:450\u001b[0m, in \u001b[0;36mJinaBertSelfOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor\n\u001b[1;32m    449\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 450\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    452\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
      "File \u001b[0;32m~/miniconda3/envs/embenchmark2/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/embenchmark2/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/embenchmark2/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_lengths = [10, 20, 50, 100, 200, 500, 1000, 2000, 5000, 8192]\n",
    "\n",
    "for max_length in max_lengths:\n",
    "  result = evaluate(model, dataset, max_length=max_length)\n",
    "  print(max_length, result)\n",
    "  # append line to file\n",
    "  with open(f\"results_max_length.txt\", \"a\") as file:\n",
    "    file.write(f\"\\\"{max_length}\\\": {result},\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bge_results = {\n",
    "    \"10\": {\"v_measure\": 0.004265486331663628, \"v_measure_std\": 0.0},\n",
    "    \"20\": {\"v_measure\": 0.014783134246078416, \"v_measure_std\": 0.0},\n",
    "    \"50\": {\"v_measure\": 0.0653603311357436, \"v_measure_std\": 0.0},\n",
    "    \"100\": {\"v_measure\": 0.12984256806534275, \"v_measure_std\": 0.0},\n",
    "    \"200\": {\"v_measure\": 0.16736094418479605, \"v_measure_std\": 0.0},\n",
    "    \"500\": {\"v_measure\": 0.21870875074933765, \"v_measure_std\": 0.0},\n",
    "    \"1000\": {\"v_measure\": 0.21870875074933765, \"v_measure_std\": 0.0},\n",
    "    \"2000\": {\"v_measure\": 0.218708750749337650, \"v_measure_std\": 0.0},\n",
    "    \"5000\": {\"v_measure\": 0.21870875074933765, \"v_measure_std\": 0.0},\n",
    "    \"8192\": {\"v_measure\":0.21870875074933765, \"v_measure_std\": 0.0},\n",
    "}\n",
    "\n",
    "jina_results = {\n",
    "    \"10\": {\"v_measure\": 0.20267838077891376, \"v_measure_std\": 0.0},\n",
    "    \"20\": {\"v_measure\": 0.237214610178106, \"v_measure_std\": 0.0},\n",
    "    \"50\": {\"v_measure\": 0.27836851841068155, \"v_measure_std\": 0.0},\n",
    "    \"100\": {\"v_measure\": 0.1867017971428439, \"v_measure_std\": 0.0},\n",
    "    \"200\": {\"v_measure\": 0.3521228946014008, \"v_measure_std\": 0.0},\n",
    "    \"500\": {\"v_measure\": 0.24973108569093466, \"v_measure_std\": 0.0},\n",
    "    \"10\": {\"v_measure\": 0.0044920434783157085, \"v_measure_std\": 0.0},\n",
    "    \"20\": {\"v_measure\": 0.005988463987034339, \"v_measure_std\": 0.0},\n",
    "    \"50\": {\"v_measure\": 0.08207954056533083, \"v_measure_std\": 0.0},\n",
    "    \"100\": {\"v_measure\": 0.11879162039782026, \"v_measure_std\": 0.0},\n",
    "    \"200\": {\"v_measure\": 0.15729830446885912, \"v_measure_std\": 0.0},\n",
    "    \"500\": {\"v_measure\": 0.2275371129887451, \"v_measure_std\": 0.0},\n",
    "    \"1000\": {\"v_measure\": 0.2382059299783621, \"v_measure_std\": 0.0},\n",
    "    \"2000\": {\"v_measure\": 0.2262169460580266, \"v_measure_std\": 0.0},\n",
    "    \"5000\": {\"v_measure\": 0.23757748463911024, \"v_measure_std\": 0.0},\n",
    "    \"8192\": {\"v_measure\": 0.23196095985211845, \"v_measure_std\": 0.0},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split: 2000\n",
    "2000 :  {'v_measure': 0.8144683159455076, 'v_measure_std': 0.0}\n",
    "Split: 5000\n",
    "5000 :  {'v_measure': 0.8143484186457459, 'v_measure_std': 0.0}\n",
    "Split: 10000\n",
    "10000 :  {'v_measure': 0.8205899050814626, 'v_measure_std': 0.0}\n",
    "Split: 20000\n",
    "20000 :  {'v_measure': 0.7590519167416516, 'v_measure_std': 0.0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot results\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Inter\"\n",
    "plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(\"color\", [ \"#4269D0\",\"#3BA951\", \"#EFB117\", \"#FF725C\"])\n",
    "\n",
    "\n",
    "# plot gte and jina results in one plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = np.arange(len(jina_results))\n",
    "\n",
    "rects1 = ax.bar(x - 0.2, [bge_results[str(split)][\"v_measure\"] for split in bge_results], 0.4, label='GTE')\n",
    "rects2 = ax.bar(x + 0.2, [jina_results[str(split)][\"v_measure\"] for split in jina_results], 0.4, label='Jina')\n",
    "\n",
    "ax.set_ylabel('V-Measure')\n",
    "ax.set_xlabel('Maximum sequence length (tokens)')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(jina_results.keys())\n",
    "\n",
    "# add title\n",
    "ax.set_title('Big Patent Clustering Benchmark')\n",
    "\n",
    "ax.legend()\n",
    "plt.savefig('./results/clustering/big_patent_cutoff.png', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embenchmark2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
